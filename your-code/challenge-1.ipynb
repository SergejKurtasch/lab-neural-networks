{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1 - Tic Tac Toe\n",
    "\n",
    "In this lab you will perform deep learning analysis on a dataset of playing [Tic Tac Toe](https://en.wikipedia.org/wiki/Tic-tac-toe).\n",
    "\n",
    "There are 9 grids in Tic Tac Toe that are coded as the following picture shows:\n",
    "\n",
    "![Tic Tac Toe Grids](tttboard.jpg)\n",
    "\n",
    "In the first 9 columns of the dataset you can find which marks (`x` or `o`) exist in the grids. If there is no mark in a certain grid, it is labeled as `b`. The last column is `class` which tells you whether Player X (who always moves first in Tic Tac Toe) wins in this configuration. Note that when `class` has the value `False`, it means either Player O wins the game or it ends up as a draw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the steps suggested below to conduct a neural network analysis using Tensorflow and Keras. You will build a deep learning model to predict whether Player X wins the game or not.\n",
    "\n",
    "## Step 1: Data Engineering\n",
    "\n",
    "This dataset is almost in the ready-to-use state so you do not need to worry about missing values and so on. Still, some simple data engineering is needed.\n",
    "\n",
    "1. Read `tic-tac-toe.csv` into a dataframe.\n",
    "1. Inspect the dataset. Determine if the dataset is reliable by eyeballing the data.\n",
    "1. Convert the categorical values to numeric in all columns.\n",
    "1. Separate the inputs and output.\n",
    "1. Normalize the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TL",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "TM",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "TR",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ML",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "MM",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "MR",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "BL",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "BM",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "BR",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "class",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "39862e03-155d-4f8d-bd6c-4bfaffe32380",
       "rows": [
        [
         "0",
         "x",
         "x",
         "x",
         "x",
         "o",
         "o",
         "x",
         "o",
         "o",
         "True"
        ],
        [
         "1",
         "x",
         "x",
         "x",
         "x",
         "o",
         "o",
         "o",
         "x",
         "o",
         "True"
        ],
        [
         "2",
         "x",
         "x",
         "x",
         "x",
         "o",
         "o",
         "o",
         "o",
         "x",
         "True"
        ],
        [
         "3",
         "x",
         "x",
         "x",
         "x",
         "o",
         "o",
         "o",
         "b",
         "b",
         "True"
        ],
        [
         "4",
         "x",
         "x",
         "x",
         "x",
         "o",
         "o",
         "b",
         "o",
         "b",
         "True"
        ],
        [
         "5",
         "x",
         "x",
         "x",
         "x",
         "o",
         "o",
         "b",
         "b",
         "o",
         "True"
        ],
        [
         "6",
         "x",
         "x",
         "x",
         "x",
         "o",
         "b",
         "o",
         "o",
         "b",
         "True"
        ],
        [
         "7",
         "x",
         "x",
         "x",
         "x",
         "o",
         "b",
         "o",
         "b",
         "o",
         "True"
        ],
        [
         "8",
         "x",
         "x",
         "x",
         "x",
         "o",
         "b",
         "b",
         "o",
         "o",
         "True"
        ],
        [
         "9",
         "x",
         "x",
         "x",
         "x",
         "b",
         "o",
         "o",
         "o",
         "b",
         "True"
        ],
        [
         "10",
         "x",
         "x",
         "x",
         "x",
         "b",
         "o",
         "o",
         "b",
         "o",
         "True"
        ],
        [
         "11",
         "x",
         "x",
         "x",
         "x",
         "b",
         "o",
         "b",
         "o",
         "o",
         "True"
        ],
        [
         "12",
         "x",
         "x",
         "x",
         "o",
         "x",
         "o",
         "x",
         "o",
         "o",
         "True"
        ],
        [
         "13",
         "x",
         "x",
         "x",
         "o",
         "x",
         "o",
         "o",
         "x",
         "o",
         "True"
        ],
        [
         "14",
         "x",
         "x",
         "x",
         "o",
         "x",
         "o",
         "o",
         "o",
         "x",
         "True"
        ],
        [
         "15",
         "x",
         "x",
         "x",
         "o",
         "x",
         "o",
         "o",
         "b",
         "b",
         "True"
        ],
        [
         "16",
         "x",
         "x",
         "x",
         "o",
         "x",
         "o",
         "b",
         "o",
         "b",
         "True"
        ],
        [
         "17",
         "x",
         "x",
         "x",
         "o",
         "x",
         "o",
         "b",
         "b",
         "o",
         "True"
        ],
        [
         "18",
         "x",
         "x",
         "x",
         "o",
         "x",
         "b",
         "o",
         "o",
         "b",
         "True"
        ],
        [
         "19",
         "x",
         "x",
         "x",
         "o",
         "x",
         "b",
         "o",
         "b",
         "o",
         "True"
        ],
        [
         "20",
         "x",
         "x",
         "x",
         "o",
         "x",
         "b",
         "b",
         "o",
         "o",
         "True"
        ],
        [
         "21",
         "x",
         "x",
         "x",
         "o",
         "o",
         "x",
         "x",
         "o",
         "o",
         "True"
        ],
        [
         "22",
         "x",
         "x",
         "x",
         "o",
         "o",
         "x",
         "o",
         "x",
         "o",
         "True"
        ],
        [
         "23",
         "x",
         "x",
         "x",
         "o",
         "o",
         "x",
         "o",
         "o",
         "x",
         "True"
        ],
        [
         "24",
         "x",
         "x",
         "x",
         "o",
         "o",
         "x",
         "o",
         "b",
         "b",
         "True"
        ],
        [
         "25",
         "x",
         "x",
         "x",
         "o",
         "o",
         "x",
         "b",
         "o",
         "b",
         "True"
        ],
        [
         "26",
         "x",
         "x",
         "x",
         "o",
         "o",
         "x",
         "b",
         "b",
         "o",
         "True"
        ],
        [
         "27",
         "x",
         "x",
         "x",
         "o",
         "o",
         "b",
         "x",
         "o",
         "b",
         "True"
        ],
        [
         "28",
         "x",
         "x",
         "x",
         "o",
         "o",
         "b",
         "x",
         "b",
         "o",
         "True"
        ],
        [
         "29",
         "x",
         "x",
         "x",
         "o",
         "o",
         "b",
         "o",
         "x",
         "b",
         "True"
        ],
        [
         "30",
         "x",
         "x",
         "x",
         "o",
         "o",
         "b",
         "o",
         "b",
         "x",
         "True"
        ],
        [
         "31",
         "x",
         "x",
         "x",
         "o",
         "o",
         "b",
         "b",
         "x",
         "o",
         "True"
        ],
        [
         "32",
         "x",
         "x",
         "x",
         "o",
         "o",
         "b",
         "b",
         "o",
         "x",
         "True"
        ],
        [
         "33",
         "x",
         "x",
         "x",
         "o",
         "o",
         "b",
         "b",
         "b",
         "b",
         "True"
        ],
        [
         "34",
         "x",
         "x",
         "x",
         "o",
         "b",
         "x",
         "o",
         "o",
         "b",
         "True"
        ],
        [
         "35",
         "x",
         "x",
         "x",
         "o",
         "b",
         "x",
         "o",
         "b",
         "o",
         "True"
        ],
        [
         "36",
         "x",
         "x",
         "x",
         "o",
         "b",
         "x",
         "b",
         "o",
         "o",
         "True"
        ],
        [
         "37",
         "x",
         "x",
         "x",
         "o",
         "b",
         "o",
         "x",
         "o",
         "b",
         "True"
        ],
        [
         "38",
         "x",
         "x",
         "x",
         "o",
         "b",
         "o",
         "x",
         "b",
         "o",
         "True"
        ],
        [
         "39",
         "x",
         "x",
         "x",
         "o",
         "b",
         "o",
         "o",
         "x",
         "b",
         "True"
        ],
        [
         "40",
         "x",
         "x",
         "x",
         "o",
         "b",
         "o",
         "o",
         "b",
         "x",
         "True"
        ],
        [
         "41",
         "x",
         "x",
         "x",
         "o",
         "b",
         "o",
         "b",
         "x",
         "o",
         "True"
        ],
        [
         "42",
         "x",
         "x",
         "x",
         "o",
         "b",
         "o",
         "b",
         "o",
         "x",
         "True"
        ],
        [
         "43",
         "x",
         "x",
         "x",
         "o",
         "b",
         "o",
         "b",
         "b",
         "b",
         "True"
        ],
        [
         "44",
         "x",
         "x",
         "x",
         "o",
         "b",
         "b",
         "x",
         "o",
         "o",
         "True"
        ],
        [
         "45",
         "x",
         "x",
         "x",
         "o",
         "b",
         "b",
         "o",
         "x",
         "o",
         "True"
        ],
        [
         "46",
         "x",
         "x",
         "x",
         "o",
         "b",
         "b",
         "o",
         "o",
         "x",
         "True"
        ],
        [
         "47",
         "x",
         "x",
         "x",
         "o",
         "b",
         "b",
         "o",
         "b",
         "b",
         "True"
        ],
        [
         "48",
         "x",
         "x",
         "x",
         "o",
         "b",
         "b",
         "b",
         "o",
         "b",
         "True"
        ],
        [
         "49",
         "x",
         "x",
         "x",
         "o",
         "b",
         "b",
         "b",
         "b",
         "o",
         "True"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 958
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TL</th>\n",
       "      <th>TM</th>\n",
       "      <th>TR</th>\n",
       "      <th>ML</th>\n",
       "      <th>MM</th>\n",
       "      <th>MR</th>\n",
       "      <th>BL</th>\n",
       "      <th>BM</th>\n",
       "      <th>BR</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>958 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    TL TM TR ML MM MR BL BM BR  class\n",
       "0    x  x  x  x  o  o  x  o  o   True\n",
       "1    x  x  x  x  o  o  o  x  o   True\n",
       "2    x  x  x  x  o  o  o  o  x   True\n",
       "3    x  x  x  x  o  o  o  b  b   True\n",
       "4    x  x  x  x  o  o  b  o  b   True\n",
       "..  .. .. .. .. .. .. .. .. ..    ...\n",
       "953  o  x  x  x  o  o  o  x  x  False\n",
       "954  o  x  o  x  x  o  x  o  x  False\n",
       "955  o  x  o  x  o  x  x  o  x  False\n",
       "956  o  x  o  o  x  x  x  o  x  False\n",
       "957  o  o  x  x  x  o  o  x  x  False\n",
       "\n",
       "[958 rows x 10 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "tic_tac = pd.read_csv('tic-tac-toe.csv')\n",
    "tic_tac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted data:\n",
      "   TL  TM  TR  ML  MM  MR  BL  BM  BR  class\n",
      "0   1   1   1   1  -1  -1   1  -1  -1      1\n",
      "1   1   1   1   1  -1  -1  -1   1  -1      1\n",
      "2   1   1   1   1  -1  -1  -1  -1   1      1\n",
      "3   1   1   1   1  -1  -1  -1   0   0      1\n",
      "4   1   1   1   1  -1  -1   0  -1   0      1\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert the categorical values to numeric in all columns.\n",
    "board_mapping = {'x': 1, 'o': -1, 'b': 0}\n",
    "class_mapping = {True: 1, False: 0}\n",
    "\n",
    "for col in tic_tac.columns[:-1]:\n",
    "    tic_tac[col] = tic_tac[col].map(board_mapping)\n",
    "\n",
    "tic_tac['class'] = tic_tac['class'].map(class_mapping)\n",
    "\n",
    "print(\"Converted data:\")\n",
    "print(tic_tac.head())\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data (X):\n",
      "   TL  TM  TR  ML  MM  MR  BL  BM  BR\n",
      "0   1   1   1   1  -1  -1   1  -1  -1\n",
      "1   1   1   1   1  -1  -1  -1   1  -1\n",
      "2   1   1   1   1  -1  -1  -1  -1   1\n",
      "3   1   1   1   1  -1  -1  -1   0   0\n",
      "4   1   1   1   1  -1  -1   0  -1   0\n",
      "\\Output data (y):\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: class, dtype: int64\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Separate the inputs and output.\n",
    "X = tic_tac.iloc[:, :-1]\n",
    "y = tic_tac.iloc[:, -1]\n",
    "\n",
    "print(\"Input data (X):\")\n",
    "print(X.head())\n",
    "print(\"\\Output data (y):\")\n",
    "print(y.head())\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized data (X_normalized):\n",
      "        TL       TM       TR       ML        MM        MR        BL        BM  \\\n",
      "0  1.03517  1.10683  1.03517  1.10683 -1.241994 -1.223594  1.035170 -1.223594   \n",
      "1  1.03517  1.10683  1.03517  1.10683 -1.241994 -1.223594 -1.231556  1.106830   \n",
      "2  1.03517  1.10683  1.03517  1.10683 -1.241994 -1.223594 -1.231556 -1.223594   \n",
      "3  1.03517  1.10683  1.03517  1.10683 -1.241994 -1.223594 -1.231556 -0.058382   \n",
      "4  1.03517  1.10683  1.03517  1.10683 -1.241994 -1.223594 -0.098193 -1.223594   \n",
      "\n",
      "         BR  \n",
      "0 -1.231556  \n",
      "1 -1.231556  \n",
      "2  1.035170  \n",
      "3 -0.098193  \n",
      "4 -0.098193  \n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "X_normalized_df = pd.DataFrame(X_normalized, columns=X.columns)\n",
    "\n",
    "print(\"Normalized data (X_normalized):\")\n",
    "print(X_normalized_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Build Neural Network\n",
    "\n",
    "To build the neural network, you can refer to your own codes you wrote while following the [Deep Learning with Python, TensorFlow, and Keras tutorial](https://www.youtube.com/watch?v=wQ8BIBpya2k) in the lesson. It's pretty similar to what you will be doing in this lab.\n",
    "\n",
    "1. Split the training and test data.\n",
    "1. Create a `Sequential` model.\n",
    "1. Add several layers to your model. Make sure you use ReLU as the activation function for the middle layers. Use Softmax for the output layer because each output has a single lable and all the label probabilities add up to 1.\n",
    "1. Compile the model using `adam` as the optimizer and `sparse_categorical_crossentropy` as the loss function. For metrics, use `accuracy` for now.\n",
    "1. Fit the training data.\n",
    "1. Evaluate your neural network model with the test data.\n",
    "1. Save your model as `tic-tac-toe.model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train sahpe: 766\n",
      "X_test shape: 192\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergej/Library/Mobile Documents/com~apple~CloudDocs/DS_AI/python_projects/tf_env/lib/python3.11/site-packages/keras/src/layers/core/dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m66\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,786</span> (10.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,786\u001b[0m (10.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,786</span> (10.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,786\u001b[0m (10.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_normalized, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"X_train sahpe: {X_train.shape[0]}\")\n",
    "print(f\"X_test shape: {X_test.shape[0]}\")\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "#Create a `Sequential` model.\n",
    "n_features = X_train.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(n_features,)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the model...\n",
      "Epoch 1/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.5522 - loss: 0.7411 - val_accuracy: 0.6927 - val_loss: 0.5899\n",
      "Epoch 2/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6906 - loss: 0.5557 - val_accuracy: 0.7344 - val_loss: 0.5382\n",
      "Epoch 3/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7533 - loss: 0.5009 - val_accuracy: 0.7448 - val_loss: 0.4900\n",
      "Epoch 4/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8081 - loss: 0.4549 - val_accuracy: 0.8177 - val_loss: 0.4451\n",
      "Epoch 5/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8381 - loss: 0.4093 - val_accuracy: 0.8490 - val_loss: 0.3974\n",
      "Epoch 6/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8943 - loss: 0.3596 - val_accuracy: 0.9219 - val_loss: 0.3509\n",
      "Epoch 7/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9452 - loss: 0.3096 - val_accuracy: 0.9531 - val_loss: 0.3011\n",
      "Epoch 8/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9765 - loss: 0.2570 - val_accuracy: 0.9740 - val_loss: 0.2548\n",
      "Epoch 9/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.9856 - loss: 0.2122 - val_accuracy: 0.9740 - val_loss: 0.2182\n",
      "Epoch 10/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.9856 - loss: 0.1759 - val_accuracy: 0.9740 - val_loss: 0.1878\n",
      "Epoch 11/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.9856 - loss: 0.1469 - val_accuracy: 0.9740 - val_loss: 0.1684\n",
      "Epoch 12/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9856 - loss: 0.1254 - val_accuracy: 0.9740 - val_loss: 0.1517\n",
      "Epoch 13/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.9856 - loss: 0.1136 - val_accuracy: 0.9740 - val_loss: 0.1406\n",
      "Epoch 14/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9856 - loss: 0.0986 - val_accuracy: 0.9740 - val_loss: 0.1362\n",
      "Epoch 15/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9856 - loss: 0.0926 - val_accuracy: 0.9740 - val_loss: 0.1304\n",
      "Epoch 16/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9856 - loss: 0.0871 - val_accuracy: 0.9740 - val_loss: 0.1307\n",
      "Epoch 17/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9856 - loss: 0.0852 - val_accuracy: 0.9740 - val_loss: 0.1268\n",
      "Epoch 18/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9856 - loss: 0.0815 - val_accuracy: 0.9740 - val_loss: 0.1302\n",
      "Epoch 19/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9856 - loss: 0.0830 - val_accuracy: 0.9740 - val_loss: 0.1265\n",
      "Epoch 20/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9856 - loss: 0.0801 - val_accuracy: 0.9740 - val_loss: 0.1276\n",
      "Epoch 21/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9856 - loss: 0.0761 - val_accuracy: 0.9740 - val_loss: 0.1259\n",
      "Epoch 22/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9856 - loss: 0.0757 - val_accuracy: 0.9740 - val_loss: 0.1237\n",
      "Epoch 23/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9856 - loss: 0.0758 - val_accuracy: 0.9740 - val_loss: 0.1307\n",
      "Epoch 24/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0755 - val_accuracy: 0.9740 - val_loss: 0.1287\n",
      "Epoch 25/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.9856 - loss: 0.0755 - val_accuracy: 0.9740 - val_loss: 0.1253\n",
      "Epoch 26/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9856 - loss: 0.0768 - val_accuracy: 0.9740 - val_loss: 0.1273\n",
      "Epoch 27/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9856 - loss: 0.0718 - val_accuracy: 0.9740 - val_loss: 0.1270\n",
      "Epoch 28/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9856 - loss: 0.0745 - val_accuracy: 0.9740 - val_loss: 0.1287\n",
      "Epoch 29/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9856 - loss: 0.0718 - val_accuracy: 0.9740 - val_loss: 0.1229\n",
      "Epoch 30/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9856 - loss: 0.0743 - val_accuracy: 0.9740 - val_loss: 0.1366\n",
      "Epoch 31/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9856 - loss: 0.0748 - val_accuracy: 0.9740 - val_loss: 0.1298\n",
      "Epoch 32/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9856 - loss: 0.0739 - val_accuracy: 0.9740 - val_loss: 0.1264\n",
      "Epoch 33/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9856 - loss: 0.0755 - val_accuracy: 0.9740 - val_loss: 0.1298\n",
      "Epoch 34/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9856 - loss: 0.0770 - val_accuracy: 0.9740 - val_loss: 0.1358\n",
      "Epoch 35/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9856 - loss: 0.0763 - val_accuracy: 0.9740 - val_loss: 0.1296\n",
      "Epoch 36/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9856 - loss: 0.0721 - val_accuracy: 0.9740 - val_loss: 0.1288\n",
      "Epoch 37/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9856 - loss: 0.0749 - val_accuracy: 0.9740 - val_loss: 0.1300\n",
      "Epoch 38/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9856 - loss: 0.0767 - val_accuracy: 0.9740 - val_loss: 0.1302\n",
      "Epoch 39/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9856 - loss: 0.0752 - val_accuracy: 0.9740 - val_loss: 0.1330\n",
      "Epoch 40/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9856 - loss: 0.0792 - val_accuracy: 0.9740 - val_loss: 0.1335\n",
      "Epoch 41/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9856 - loss: 0.0767 - val_accuracy: 0.9740 - val_loss: 0.1268\n",
      "Epoch 42/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9856 - loss: 0.0761 - val_accuracy: 0.9740 - val_loss: 0.1300\n",
      "Epoch 43/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9856 - loss: 0.0737 - val_accuracy: 0.9740 - val_loss: 0.1343\n",
      "Epoch 44/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.9856 - loss: 0.0719 - val_accuracy: 0.9740 - val_loss: 0.1277\n",
      "Epoch 45/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9856 - loss: 0.0763 - val_accuracy: 0.9740 - val_loss: 0.1337\n",
      "Epoch 46/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9856 - loss: 0.0739 - val_accuracy: 0.9740 - val_loss: 0.1411\n",
      "Epoch 47/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.9856 - loss: 0.0743 - val_accuracy: 0.9740 - val_loss: 0.1328\n",
      "Epoch 48/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.9856 - loss: 0.0717 - val_accuracy: 0.9740 - val_loss: 0.1359\n",
      "Epoch 49/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9856 - loss: 0.0754 - val_accuracy: 0.9740 - val_loss: 0.1376\n",
      "Epoch 50/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9856 - loss: 0.0763 - val_accuracy: 0.9740 - val_loss: 0.1303\n",
      "\n",
      "==================================================\n",
      "\n",
      "Test data evaluation:\n",
      "Test data loss: 0.1303\n",
      "Test data accuracy: 0.9740\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compile the model using `adam` as the optimizer and `sparse_categorical_crossentropy` as the loss function. For metrics, use `accuracy` for now.\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "# Fit the training data.\n",
    "\n",
    "print(\"Fitting the model...\")\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test), \n",
    "    verbose=1 \n",
    ")\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Evaluate your neural network model with the test data.\n",
    "print(\"Test data evaluation:\")\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test data loss: {loss:.4f}\")\n",
    "print(f\"Test data accuracy: {accuracy:.4f}\")\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model was saved : 'tic-tac-toe.keras'\n",
      "Path: /Users/sergej/Library/Mobile Documents/com~apple~CloudDocs/DS_AI/python_projects/week31-DL/lab-neural-networks/your-code/tic-tac-toe.keras\n"
     ]
    }
   ],
   "source": [
    "# Save your model as `tic-tac-toe.model`.\n",
    "\n",
    "import os\n",
    "\n",
    "model_save_path = \"tic-tac-toe.keras\"\n",
    "model.save(model_save_path)\n",
    "print(f\"The model was saved : '{model_save_path}'\")\n",
    "print(f\"Path: {os.path.abspath(model_save_path)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Make Predictions\n",
    "\n",
    "Now load your saved model and use it to make predictions on a few random rows in the test dataset. Check if the predictions are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\n",
      "Check predictions:\n",
      "Example 1:\n",
      "  Input data: [-1.23155602 -1.2235944   1.03516957  1.10682993 -0.13620382  1.10682993\n",
      " -1.23155602 -0.05838224  1.03516957]\n",
      "  Real class: 1 (win X: True)\n",
      "  Predicted class: 1 (win X: True)\n",
      "  Result: Correct\n",
      "\n",
      "Example 2:\n",
      "  Input data: [-1.23155602 -1.2235944  -0.09819323 -0.05838224  0.96958654 -1.2235944\n",
      "  1.03516957  1.10682993  1.03516957]\n",
      "  Real class: 1 (win X: True)\n",
      "  Predicted class: 1 (win X: True)\n",
      "  Result: Correct\n",
      "\n",
      "Example 3:\n",
      "  Input data: [-0.09819323 -1.2235944  -1.23155602  1.10682993 -1.24199419 -0.05838224\n",
      "  1.03516957  1.10682993  1.03516957]\n",
      "  Real class: 1 (win X: True)\n",
      "  Predicted class: 1 (win X: True)\n",
      "  Result: Correct\n",
      "\n",
      "Example 4:\n",
      "  Input data: [ 1.03516957  1.10682993  1.03516957 -1.2235944  -0.13620382  1.10682993\n",
      " -1.23155602 -1.2235944  -0.09819323]\n",
      "  Real class: 1 (win X: True)\n",
      "  Predicted class: 1 (win X: True)\n",
      "  Result: Correct\n",
      "\n",
      "Example 5:\n",
      "  Input data: [ 1.03516957 -0.05838224  1.03516957 -1.2235944  -1.24199419 -1.2235944\n",
      " -0.09819323 -0.05838224  1.03516957]\n",
      "  Real class: 0 (win X: False)\n",
      "  Predicted class: 0 (win X: False)\n",
      "  Result: Correct\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "loaded_model = tf.keras.models.load_model(model_save_path)\n",
    "\n",
    "random_indices = np.random.randint(0, len(X_test), 5)\n",
    "sample_X = X_test[random_indices]\n",
    "sample_y = y_test.iloc[random_indices]\n",
    "\n",
    "predictions = loaded_model.predict(sample_X)\n",
    "\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "print(\"\\nCheck predictions:\")\n",
    "for i in range(len(random_indices)):\n",
    "    actual_label = sample_y.iloc[i]\n",
    "    predicted_label = predicted_classes[i]\n",
    "    is_correct = \"Correct\" if actual_label == predicted_label else \"Wrong\"\n",
    "    print(f\"Example {i+1}:\")\n",
    "    print(f\"  Input data: {sample_X[i]}\")\n",
    "    print(f\"  Real class: {actual_label} (win X: {actual_label == 1})\")\n",
    "    print(f\"  Predicted class: {predicted_label} (win X: {predicted_label == 1})\")\n",
    "    print(f\"  Result: {is_correct}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Improve Your Model\n",
    "\n",
    "Did your model achieve low loss (<0.1) and high accuracy (>0.95)? If not, try to improve your model.\n",
    "\n",
    "But how? There are so many things you can play with in Tensorflow and in the next challenge you'll learn about these things. But in this challenge, let's just do a few things to see if they will help.\n",
    "\n",
    "* Add more layers to your model. If the data are complex you need more layers. But don't use more layers than you need. If adding more layers does not improve the model performance you don't need additional layers.\n",
    "* Adjust the learning rate when you compile the model. This means you will create a custom `tf.keras.optimizers.Adam` instance where you specify the learning rate you want. Then pass the instance to `model.compile` as the optimizer.\n",
    "    * `tf.keras.optimizers.Adam` [reference](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam).\n",
    "    * Don't worry if you don't understand what the learning rate does. You'll learn about it in the next challenge.\n",
    "* Adjust the number of epochs when you fit the training data to the model. Your model performance continues to improve as you train more epochs. But eventually it will reach the ceiling and the performance will stay the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergej/Library/Mobile Documents/com~apple~CloudDocs/DS_AI/python_projects/tf_env/lib/python3.11/site-packages/keras/src/layers/core/dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m34\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,282</span> (12.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,282\u001b[0m (12.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,282</span> (12.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,282\u001b[0m (12.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(n_features,)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the model...\n",
      "Epoch 1/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5444 - loss: 0.7709 - val_accuracy: 0.5677 - val_loss: 0.6649\n",
      "Epoch 2/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6462 - loss: 0.5991 - val_accuracy: 0.6979 - val_loss: 0.5882\n",
      "Epoch 3/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7063 - loss: 0.5518 - val_accuracy: 0.7344 - val_loss: 0.5539\n",
      "Epoch 4/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7258 - loss: 0.5263 - val_accuracy: 0.7292 - val_loss: 0.5327\n",
      "Epoch 5/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7428 - loss: 0.5064 - val_accuracy: 0.7448 - val_loss: 0.5083\n",
      "Epoch 6/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7546 - loss: 0.4844 - val_accuracy: 0.7448 - val_loss: 0.4921\n",
      "Epoch 7/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7807 - loss: 0.4657 - val_accuracy: 0.7708 - val_loss: 0.4730\n",
      "Epoch 8/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7977 - loss: 0.4457 - val_accuracy: 0.7969 - val_loss: 0.4525\n",
      "Epoch 9/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8133 - loss: 0.4251 - val_accuracy: 0.8125 - val_loss: 0.4299\n",
      "Epoch 10/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8460 - loss: 0.4020 - val_accuracy: 0.8385 - val_loss: 0.4095\n",
      "Epoch 11/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8642 - loss: 0.3790 - val_accuracy: 0.8542 - val_loss: 0.3822\n",
      "Epoch 12/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8877 - loss: 0.3506 - val_accuracy: 0.8854 - val_loss: 0.3550\n",
      "Epoch 13/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9112 - loss: 0.3235 - val_accuracy: 0.9167 - val_loss: 0.3281\n",
      "Epoch 14/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9308 - loss: 0.2911 - val_accuracy: 0.9531 - val_loss: 0.2991\n",
      "Epoch 15/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9543 - loss: 0.2623 - val_accuracy: 0.9531 - val_loss: 0.2694\n",
      "Epoch 16/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9687 - loss: 0.2337 - val_accuracy: 0.9688 - val_loss: 0.2448\n",
      "Epoch 17/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9804 - loss: 0.2054 - val_accuracy: 0.9740 - val_loss: 0.2195\n",
      "Epoch 18/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.1791 - val_accuracy: 0.9740 - val_loss: 0.1964\n",
      "Epoch 19/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.1605 - val_accuracy: 0.9740 - val_loss: 0.1805\n",
      "Epoch 20/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.1416 - val_accuracy: 0.9740 - val_loss: 0.1652\n",
      "Epoch 21/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9856 - loss: 0.1261 - val_accuracy: 0.9740 - val_loss: 0.1532\n",
      "Epoch 22/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9856 - loss: 0.1144 - val_accuracy: 0.9740 - val_loss: 0.1486\n",
      "Epoch 23/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.1053 - val_accuracy: 0.9740 - val_loss: 0.1396\n",
      "Epoch 24/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0993 - val_accuracy: 0.9740 - val_loss: 0.1423\n",
      "Epoch 25/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0927 - val_accuracy: 0.9740 - val_loss: 0.1290\n",
      "Epoch 26/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9856 - loss: 0.0885 - val_accuracy: 0.9740 - val_loss: 0.1337\n",
      "Epoch 27/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0848 - val_accuracy: 0.9740 - val_loss: 0.1290\n",
      "Epoch 28/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0820 - val_accuracy: 0.9740 - val_loss: 0.1313\n",
      "Epoch 29/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0798 - val_accuracy: 0.9740 - val_loss: 0.1257\n",
      "Epoch 30/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0784 - val_accuracy: 0.9740 - val_loss: 0.1289\n",
      "Epoch 31/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0782 - val_accuracy: 0.9740 - val_loss: 0.1245\n",
      "Epoch 32/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0832 - val_accuracy: 0.9740 - val_loss: 0.1288\n",
      "Epoch 33/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9856 - loss: 0.0768 - val_accuracy: 0.9740 - val_loss: 0.1243\n",
      "Epoch 34/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0780 - val_accuracy: 0.9740 - val_loss: 0.1238\n",
      "Epoch 35/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9856 - loss: 0.0776 - val_accuracy: 0.9740 - val_loss: 0.1258\n",
      "Epoch 36/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0734 - val_accuracy: 0.9740 - val_loss: 0.1269\n",
      "Epoch 37/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0734 - val_accuracy: 0.9740 - val_loss: 0.1216\n",
      "Epoch 38/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9856 - loss: 0.0726 - val_accuracy: 0.9740 - val_loss: 0.1249\n",
      "Epoch 39/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0728 - val_accuracy: 0.9740 - val_loss: 0.1236\n",
      "Epoch 40/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0731 - val_accuracy: 0.9740 - val_loss: 0.1200\n",
      "Epoch 41/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9856 - loss: 0.0738 - val_accuracy: 0.9740 - val_loss: 0.1277\n",
      "Epoch 42/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9856 - loss: 0.0745 - val_accuracy: 0.9740 - val_loss: 0.1257\n",
      "Epoch 43/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9856 - loss: 0.0718 - val_accuracy: 0.9740 - val_loss: 0.1244\n",
      "Epoch 44/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9856 - loss: 0.0746 - val_accuracy: 0.9740 - val_loss: 0.1225\n",
      "Epoch 45/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0720 - val_accuracy: 0.9740 - val_loss: 0.1222\n",
      "Epoch 46/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0747 - val_accuracy: 0.9740 - val_loss: 0.1289\n",
      "Epoch 47/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0740 - val_accuracy: 0.9740 - val_loss: 0.1271\n",
      "Epoch 48/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9856 - loss: 0.0720 - val_accuracy: 0.9740 - val_loss: 0.1270\n",
      "Epoch 49/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9856 - loss: 0.0723 - val_accuracy: 0.9740 - val_loss: 0.1184\n",
      "Epoch 50/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0724 - val_accuracy: 0.9740 - val_loss: 0.1331\n",
      "Epoch 51/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0709 - val_accuracy: 0.9740 - val_loss: 0.1195\n",
      "Epoch 52/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0734 - val_accuracy: 0.9740 - val_loss: 0.1277\n",
      "Epoch 53/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9856 - loss: 0.0782 - val_accuracy: 0.9740 - val_loss: 0.1188\n",
      "Epoch 54/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9856 - loss: 0.0739 - val_accuracy: 0.9740 - val_loss: 0.1216\n",
      "Epoch 55/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0709 - val_accuracy: 0.9740 - val_loss: 0.1292\n",
      "Epoch 56/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0735 - val_accuracy: 0.9740 - val_loss: 0.1209\n",
      "Epoch 57/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0740 - val_accuracy: 0.9740 - val_loss: 0.1199\n",
      "Epoch 58/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9856 - loss: 0.0741 - val_accuracy: 0.9740 - val_loss: 0.1225\n",
      "Epoch 59/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0745 - val_accuracy: 0.9740 - val_loss: 0.1263\n",
      "Epoch 60/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0756 - val_accuracy: 0.9740 - val_loss: 0.1259\n",
      "Epoch 61/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0752 - val_accuracy: 0.9740 - val_loss: 0.1376\n",
      "Epoch 62/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0746 - val_accuracy: 0.9740 - val_loss: 0.1304\n",
      "Epoch 63/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0784 - val_accuracy: 0.9740 - val_loss: 0.1287\n",
      "Epoch 64/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0742 - val_accuracy: 0.9740 - val_loss: 0.1220\n",
      "Epoch 65/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0764 - val_accuracy: 0.9740 - val_loss: 0.1291\n",
      "Epoch 66/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0727 - val_accuracy: 0.9740 - val_loss: 0.1261\n",
      "Epoch 67/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0747 - val_accuracy: 0.9740 - val_loss: 0.1190\n",
      "Epoch 68/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0776 - val_accuracy: 0.9740 - val_loss: 0.1329\n",
      "Epoch 69/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0753 - val_accuracy: 0.9740 - val_loss: 0.1265\n",
      "Epoch 70/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9856 - loss: 0.0727 - val_accuracy: 0.9740 - val_loss: 0.1190\n",
      "Epoch 71/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0733 - val_accuracy: 0.9740 - val_loss: 0.1167\n",
      "Epoch 72/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0747 - val_accuracy: 0.9740 - val_loss: 0.1434\n",
      "Epoch 73/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0768 - val_accuracy: 0.9740 - val_loss: 0.1224\n",
      "Epoch 74/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0755 - val_accuracy: 0.9740 - val_loss: 0.1170\n",
      "Epoch 75/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9856 - loss: 0.0752 - val_accuracy: 0.9740 - val_loss: 0.1216\n",
      "Epoch 76/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0767 - val_accuracy: 0.9740 - val_loss: 0.1325\n",
      "Epoch 77/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0746 - val_accuracy: 0.9740 - val_loss: 0.1365\n",
      "Epoch 78/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9856 - loss: 0.0789 - val_accuracy: 0.9740 - val_loss: 0.1387\n",
      "Epoch 79/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9843 - loss: 0.0837 - val_accuracy: 0.9740 - val_loss: 0.1280\n",
      "Epoch 80/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0768 - val_accuracy: 0.9740 - val_loss: 0.1518\n",
      "Epoch 81/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9856 - loss: 0.0869 - val_accuracy: 0.9740 - val_loss: 0.1251\n",
      "Epoch 82/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0872 - val_accuracy: 0.9740 - val_loss: 0.1470\n",
      "Epoch 83/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0744 - val_accuracy: 0.9740 - val_loss: 0.1255\n",
      "Epoch 84/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0737 - val_accuracy: 0.9740 - val_loss: 0.1222\n",
      "Epoch 85/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9856 - loss: 0.0754 - val_accuracy: 0.9740 - val_loss: 0.1308\n",
      "Epoch 86/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9856 - loss: 0.0745 - val_accuracy: 0.9740 - val_loss: 0.1291\n",
      "Epoch 87/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0786 - val_accuracy: 0.9740 - val_loss: 0.1278\n",
      "Epoch 88/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0772 - val_accuracy: 0.9740 - val_loss: 0.1378\n",
      "Epoch 89/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0743 - val_accuracy: 0.9740 - val_loss: 0.1251\n",
      "Epoch 90/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0807 - val_accuracy: 0.9740 - val_loss: 0.1165\n",
      "Epoch 91/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9856 - loss: 0.0730 - val_accuracy: 0.9740 - val_loss: 0.1265\n",
      "Epoch 92/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9856 - loss: 0.0750 - val_accuracy: 0.9740 - val_loss: 0.1300\n",
      "Epoch 93/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0785 - val_accuracy: 0.9740 - val_loss: 0.1202\n",
      "Epoch 94/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9843 - loss: 0.0926 - val_accuracy: 0.9740 - val_loss: 0.1489\n",
      "Epoch 95/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9830 - loss: 0.0971 - val_accuracy: 0.9740 - val_loss: 0.1283\n",
      "Epoch 96/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9856 - loss: 0.0892 - val_accuracy: 0.9740 - val_loss: 0.1343\n",
      "Epoch 97/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0759 - val_accuracy: 0.9740 - val_loss: 0.1293\n",
      "Epoch 98/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0816 - val_accuracy: 0.9740 - val_loss: 0.1210\n",
      "Epoch 99/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0786 - val_accuracy: 0.9740 - val_loss: 0.1371\n",
      "Epoch 100/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0779 - val_accuracy: 0.9740 - val_loss: 0.1268\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Fitting the model...\")\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    verbose=1 \n",
    ")\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model was saved : 'tic-tac-toe_opt.keras'\n",
      "Path: /Users/sergej/Library/Mobile Documents/com~apple~CloudDocs/DS_AI/python_projects/week31-DL/lab-neural-networks/your-code/tic-tac-toe_opt.keras\n"
     ]
    }
   ],
   "source": [
    "# Save your model as `tic-tac-toe.model`.\n",
    "\n",
    "import os\n",
    "\n",
    "model_save_path = \"tic-tac-toe_opt.keras\"\n",
    "model.save(model_save_path)\n",
    "print(f\"The model was saved : '{model_save_path}'\")\n",
    "print(f\"Path: {os.path.abspath(model_save_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step\n",
      "\n",
      "Check predictions:\n",
      "Example 1:\n",
      "  Input data: [-1.23155602  1.10682993 -0.09819323  1.10682993 -1.24199419  1.10682993\n",
      "  1.03516957 -1.2235944  -1.23155602]\n",
      "  Real class: 0 (win X: False)\n",
      "  Predicted class: 0 (win X: False)\n",
      "  Result: Correct\n",
      "\n",
      "Example 2:\n",
      "  Input data: [ 1.03516957  1.10682993 -0.09819323 -1.2235944   0.96958654 -1.2235944\n",
      " -1.23155602  1.10682993 -0.09819323]\n",
      "  Real class: 1 (win X: True)\n",
      "  Predicted class: 1 (win X: True)\n",
      "  Result: Correct\n",
      "\n",
      "Example 3:\n",
      "  Input data: [ 1.03516957 -1.2235944   1.03516957  1.10682993 -0.13620382  1.10682993\n",
      " -1.23155602 -1.2235944  -1.23155602]\n",
      "  Real class: 0 (win X: False)\n",
      "  Predicted class: 0 (win X: False)\n",
      "  Result: Correct\n",
      "\n",
      "Example 4:\n",
      "  Input data: [-0.09819323 -1.2235944   1.03516957 -0.05838224 -1.24199419  1.10682993\n",
      "  1.03516957 -1.2235944  -0.09819323]\n",
      "  Real class: 0 (win X: False)\n",
      "  Predicted class: 0 (win X: False)\n",
      "  Result: Correct\n",
      "\n",
      "Example 5:\n",
      "  Input data: [ 1.03516957  1.10682993  1.03516957 -0.05838224 -1.24199419 -0.05838224\n",
      " -0.09819323 -0.05838224 -1.23155602]\n",
      "  Real class: 1 (win X: True)\n",
      "  Predicted class: 1 (win X: True)\n",
      "  Result: Correct\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loaded_model = tf.keras.models.load_model(model_save_path)\n",
    "\n",
    "random_indices = np.random.randint(0, len(X_test), 5)\n",
    "sample_X = X_test[random_indices]\n",
    "sample_y = y_test.iloc[random_indices]\n",
    "\n",
    "predictions = loaded_model.predict(sample_X)\n",
    "\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "print(\"\\nCheck predictions:\")\n",
    "for i in range(len(random_indices)):\n",
    "    actual_label = sample_y.iloc[i]\n",
    "    predicted_label = predicted_classes[i]\n",
    "    is_correct = \"Correct\" if actual_label == predicted_label else \"Wrong\"\n",
    "    print(f\"Example {i+1}:\")\n",
    "    print(f\"  Input data: {sample_X[i]}\")\n",
    "    print(f\"  Real class: {actual_label} (win X: {actual_label == 1})\")\n",
    "    print(f\"  Predicted class: {predicted_label} (win X: {predicted_label == 1})\")\n",
    "    print(f\"  Result: {is_correct}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which approach(es) did you find helpful to improve your model performance?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here\n",
    "# Both approaches were highly effective, as they both achieved the same excellent final test accuracy of 0.9740. However, they represent a trade-off between training efficiency and final model fit.\n",
    "\n",
    "# Variant 1 is the most helpful for its efficiency. It reached maximum accuracy in a fraction of the time (8 epochs) compared to Variant 2. If the goal is to get a great result as quickly as possible, this is the superior approach.\n",
    "\n",
    "# Variant 2 is marginally more helpful for achieving a slightly better-fitting model, as evidenced by its lower final test loss of 0.1268 compared to Variant 1's 0.1303. While the accuracy is the same, the lower loss indicates the model's predictions were slightly more confident on average."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
